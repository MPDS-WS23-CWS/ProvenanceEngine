# Port for the ProvCollector to start on
server:
  port: 8083

# Prometheus
prometheus:
  server:
    url: localhost
#    url: prometheus-service.monitoring.svc.cluster.local
    port: 9090
    endpoint: "/api/v1/query"

# postgREST
pgrest:
  server:
    url: localhost
#    url: postgrest-service.db.svc.cluster.local
    port: 3000
  endpoints:
    workflows: "/workflows"
    tasks: "/tasks"
    resources: "/resources"
    resources_time_series: "/resources_time_series"

# JDBC
spring:
  sql:
    init:
      mode: always
      schema-locations: classpath:schema.sql
  datasource:
    url: jdbc:postgresql://localhost:5432/testDB
#    url: jdbc:postgresql://postgresdb.db.svc.cluster.local:5432/testDB
    username: testUser
    password: testPassword
    driver-class-name: org.postgresql.Driver

# Metrics
metrics:
  resources:
#    rate(max_over_time(container_cpu_user_seconds_total{pod=~"nf-.*"}[50m])[1m:]) *100
    cpu_max: "sum by(pod)(max_over_time(container_cpu_usage_seconds_total{namespace='cws',pod=~'nf-.*',container=~'nf-.*'}[{RANGE}]))"
    cpu_min: "sum by(pod)(min_over_time(container_cpu_usage_seconds_total{namespace='cws',pod=~'nf-.*',container=~'nf-.*'}[{RANGE}]))"
    cpu_avg: "sum by(pod)(avg_over_time(container_cpu_usage_seconds_total{namespace='cws',pod=~'nf-.*',container=~'nf-.*'}[{RANGE}]))"
    mem_max: "sum by(pod)(max_over_time(container_memory_working_set_bytes{namespace='cws',pod=~'nf-.*',container=~'nf-.*'}[{RANGE}]))"
    mem_min: "sum by(pod)(min_over_time(container_memory_working_set_bytes{namespace='cws',pod=~'nf-.*',container=~'nf-.*'}[{RANGE}]))"
    mem_avg": "sum by(pod)(avg_over_time(container_memory_working_set_bytes{namespace='cws',pod=~'nf-.*',container=~'nf-.*'}[{RANGE}]))"
    fs_reads_total: "max_over_time(container_fs_reads_bytes_total{namespace='cws',pod=~'nf-.*',container=~'nf-.*'}[{RANGE}])"
    fs_writes_total: "max_over_time(container_fs_writes_bytes_total{namespace='cws',pod=~'nf-.*',container=~'nf-.*'}[{RANGE}])"
  resources_time_series:
    cpu: "container_cpu_usage_seconds_total{namespace='cws',pod=~'nf-.*',container=~'nf-.*'}[{RANGE}]"
# Pod query profile:

# We don't need POD INFO Stuff as this can be hardcoded in the metrics-client just as it is
# Just for understanding:

# kube_pod_created
# kube_pod_completion_time

# PROMQL:
# Start time:
# sum by(pod,uid)(kube_pod_created{namespace="cws"})

# Completion time:
# sum by(pod,uid)(kube_pod_completion_time{namespace="cws"})

# Specific pod:
# sum by(pod,uid)(kube_pod_created{namespace="cws", uid="96ae7716-895e-4e88-b214-802524d6020f"})

# kube_pod_info

# PROMQL:
# all pods in namespace="cws"
# kube_pod_info{namespace="cws"}

# less JSON information, node to see on which node it ran
# sum by(namespace,node,pod,uid) kube_pod_info{namespace="cws"}

# ---Termination Info---
# -METRIC NAME-
# kube_pod_container_status_last_terminated_reason

# PROMQL:
# specific pod by "uid"
# sum by(reason, uid) (kube_pod_container_status_last_terminated_reason{uid="..."})

# all pods
# sum by(reason, uid,pod) (kube_pod_container_status_last_terminated_reason)

# might be worth a look
# sum by(uid, phase)(kube_pod_status_phase)

# Our point-of-interst are the infrastructure-level resource metrics for POD & NODE:

# metrics.pod.profiles=

# container_CPU_usage_seconds_total

# sum by(pod)(max_over_time(container_cpu_usage_seconds_total{namespace="cws"}[1h]))

# sum by(pod)(min_over_time(container_cpu_usage_seconds_total{namespace="cws"}[1h]))

# sum by(pod)(avg_over_time(container_cpu_usage_seconds_total{namespace="cws"}[1h]))

# container_memory_working_set_bytes

# container_memory_max_usage_bytes

# container_memory_usage_bytes

# sum by(pod)(max_over_time(container_memory_working_set_bytes{namespace="cws"}[1h]))

# kube_pod_container_resource_requests

# sum by(pod, uid, unit) (kube_pod_container_resource_requests{namespace="cws"})


# NODE query profile:
# metrics.node.profiles=

# ------NODE INFO------
# ---CPU USAGE---
# METRIC NAME-
# node_cpu_seconds_total

# PROMQL:
# dont quite understand output
# node_cpu_seconds_total

# ---CPU ALLOCATABLE RESOURCES---
# -METRIC NAME-
# kube_node_status_allocatable

# PROMQL:
# get allocatable bytes
# sum by(node, unit) (kube_node_status_allocatable{resource="memory"})

# get allocatable cpus
# sum by(node, unit) (kube_node_status_allocatable{resource="cpu"})

# node_memory_MemFree_bytes
# node_memory_Buffers_bytes
# node_memory_MemTotal_bytes