# Port for the ProvCollector to start on
server:
  port: 8083
  
# Prometheus
prometheus:
  server:
    url: http://localhost:9090/api/v1/query


# postgREST
pgrest:
  server:
    url: http://localhost:3000
  endpoints:
    workflows: "/workflows"
    tasks: "/tasks"
    resources: "/resources"

# JDBC
spring:
  sql:
    init:
      mode: always
      schema-locations: classpath:schema.sql
  datasource:
    url: jdbc:postgresql://localhost:5432/testDB
    username: testUser
    password: testPassword
    driver-class-name: org.postgresql.Driver

# Metrics
metrics:
  resources:
    cpu_max: "sum by(pod)(max_over_time(container_cpu_usage_seconds_total{pod=~'nf-.*'}[{RANGE}]))"
    cpu_min: "sum by(pod)(min_over_time(container_cpu_usage_seconds_total{pod=~'nf-.*'}[{RANGE}]))"
    cpu_avg: "sum by(pod)(avg_over_time(container_cpu_usage_seconds_total{pod=~'nf-.*'}[{RANGE}]))"
    mem_max: "sum by(pod)(max_over_time(container_memory_working_set_bytes{pod=~'nf-.*'}[{RANGE}]))"
    mem_min: "sum by(pod)(min_over_time(container_memory_working_set_bytes{pod=~'nf-.*'}[{RANGE}]))"
    mem_avg": "sum by(pod)(avg_over_time(container_memory_working_set_bytes{pod=~'nf-.*'}[{RANGE}]))"


# Pod query profile:

# We don't need POD INFO Stuff as this can be hardcoded in the metrics-client just as it is
# Just for understanding:

# kube_pod_created
# kube_pod_completion_time

# PROMQL:
# Start time:
# sum by(pod,uid)(kube_pod_created{namespace="cws"})

# Completion time:
# sum by(pod,uid)(kube_pod_completion_time{namespace="cws"})

# Specific pod:
# sum by(pod,uid)(kube_pod_created{namespace="cws", uid="96ae7716-895e-4e88-b214-802524d6020f"})

# kube_pod_info

# PROMQL:
# all pods in namespace="cws"
# kube_pod_info{namespace="cws"}

# less JSON information, node to see on which node it ran
# sum by(namespace,node,pod,uid) kube_pod_info{namespace="cws"}

# ---Termination Info---
# -METRIC NAME-
# kube_pod_container_status_last_terminated_reason

# PROMQL:
# specific pod by "uid"
# sum by(reason, uid) (kube_pod_container_status_last_terminated_reason{uid="..."})

# all pods
# sum by(reason, uid,pod) (kube_pod_container_status_last_terminated_reason)

# might be worth a look
# sum by(uid, phase)(kube_pod_status_phase)

# Our point-of-interst are the infrastructure-level resource metrics for POD & NODE:

# metrics.pod.profiles=

# container_CPU_usage_seconds_total

# sum by(pod)(max_over_time(container_cpu_usage_seconds_total{namespace="cws"}[1h]))

# sum by(pod)(min_over_time(container_cpu_usage_seconds_total{namespace="cws"}[1h]))

# sum by(pod)(avg_over_time(container_cpu_usage_seconds_total{namespace="cws"}[1h]))

# container_memory_working_set_bytes

# container_memory_max_usage_bytes

# container_memory_usage_bytes

# sum by(pod)(max_over_time(container_memory_working_set_bytes{namespace="cws"}[1h]))

# kube_pod_container_resource_requests

# sum by(pod, uid, unit) (kube_pod_container_resource_requests{namespace="cws"})


# NODE query profile:
# metrics.node.profiles=

# ------NODE INFO------
# ---CPU USAGE---
# METRIC NAME-
# node_cpu_seconds_total

# PROMQL:
# dont quite understand output
# node_cpu_seconds_total

# ---CPU ALLOCATABLE RESOURCES---
# -METRIC NAME-
# kube_node_status_allocatable

# PROMQL:
# get allocatable bytes
# sum by(node, unit) (kube_node_status_allocatable{resource="memory"})

# get allocatable cpus
# sum by(node, unit) (kube_node_status_allocatable{resource="cpu"})

# node_memory_MemFree_bytes
# node_memory_Buffers_bytes
# node_memory_MemTotal_bytes